{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarks\n",
    "\n",
    "Benchmarks to help with design/architecture decisions of the lib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tqdm\n",
    "from datasets import load_dataset\n",
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "from sparse_autoencoder.autoencoder.model import SparseAutoencoder\n",
    "from sparse_autoencoder.dataset.dataloader import (\n",
    "    collate_neel_c4_tokenized,\n",
    "    create_dataloader,\n",
    ")\n",
    "from sparse_autoencoder.train.train import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Tensor Sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's useful to know both the size and how much it can be compressed/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7fc4e7d17264347b1fe15d48bd74fb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Number of activations to store: 25600'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a batch of text data\n",
    "dataset = load_dataset(\"NeelNanda/c4-code-tokenized-2b\", split=\"train\", streaming=True)\n",
    "first_batch = []\n",
    "for idx, example in enumerate(dataset):\n",
    "    if not idx <= 24:\n",
    "        break\n",
    "    first_batch.append(example[\"tokens\"])\n",
    "first_batch = torch.tensor(first_batch)\n",
    "f\"Number of activations to store: {first_batch.numel()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model NeelNanda/GELU_1L512W_C4_Code into HookedTransformer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'With 52428800 features at half precision, the features take up 104.86 MB of memory'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the activations\n",
    "src_model = HookedTransformer.from_pretrained(\"NeelNanda/GELU_1L512W_C4_Code\")\n",
    "logits, cache = src_model.run_with_cache(first_batch)\n",
    "activations = cache[\"blocks.0.mlp.hook_post\"].half()\n",
    "number_activations = activations.numel()\n",
    "size_bytes_activations = number_activations * 2  # Assume float 16\n",
    "size_mb_activations = f\"{size_bytes_activations / (10**6):.2f} MB\"\n",
    "f\"With {activations.numel()} features at half precision, the features take up {size_mb_activations} of memory\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we try compressing on the disk (and find the impact is small so probably not worth it):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Compressed file size is 93.09 MB'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save to temp dir\n",
    "temp_dir = tempfile.gettempdir()\n",
    "temp_file = temp_dir + \"/temp.pt\"\n",
    "temp_file_gz = temp_file + \".gz\"\n",
    "torch.save(activations, temp_file)\n",
    "\n",
    "# Zip it\n",
    "with open(temp_file, \"rb\") as f_in:\n",
    "    with gzip.open(temp_file_gz, \"wb\") as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "# Get the file size back\n",
    "fs_bytes = os.path.getsize(temp_file_gz)\n",
    "f\"Compressed file size is {fs_bytes / (10**6):.2f} MB\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's calculate assuming 8 billion activations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'With 8000000000 batches of 2048 activations, the estimated size is 32.77 TB'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assumed_n_activation_batches = 8 * (10**9)\n",
    "assumed_n_activations_per_batch = 2048\n",
    "uncompressed_size_per_activation = 2  # float16\n",
    "estimated_size = (\n",
    "    assumed_n_activation_batches\n",
    "    * assumed_n_activations_per_batch\n",
    "    * uncompressed_size_per_activation\n",
    ")\n",
    "f\"With {assumed_n_activation_batches} batches of {assumed_n_activations_per_batch} activations, \\\n",
    "the estimated size is {estimated_size / (10**12):.2f} TB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size (GB)</th>\n",
       "      <th>Activations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>2M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>12M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>24M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300</td>\n",
       "      <td>73M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500</td>\n",
       "      <td>122M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000</td>\n",
       "      <td>244M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Size (GB) Activations\n",
       "0         10          2M\n",
       "1         50         12M\n",
       "2        100         24M\n",
       "3        300         73M\n",
       "4        500        122M\n",
       "5       1000        244M"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the amount of activations you can store with different sizes\n",
    "\n",
    "sizes_gb = [10, 50, 100, 300, 500, 1000]\n",
    "activations_per_size = [\n",
    "    i * (10**9) / uncompressed_size_per_activation / assumed_n_activations_per_batch\n",
    "    for i in sizes_gb\n",
    "]\n",
    "\n",
    "table = pd.DataFrame({\"Size (GB)\": sizes_gb, \"Activations\": activations_per_size})\n",
    "table[\"Activations\"] = table[\"Activations\"].apply(\n",
    "    lambda x: \"{:,.0f}\".format(x / 10**6) + \"M\"\n",
    ")\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VastAI systems often have quite a lot of HD space (e.g. 300GB) but available ram is often smaller\n",
    "(e.g. 50GB and we need a reasonable amount left over for moving tensors around etc). This means that\n",
    "we can store c. 5-10M activations on a typical instance in CPU RAM (sometimes 25M+), or 50-100M on\n",
    "disk. Both seem like plenty!\n",
    "\n",
    "To note that replenishing a buffer of cached activations when half used in training seems like a lot\n",
    "of pain, considering that the improvement is likely marginal. Particularly if we also randomly sort\n",
    "the prompts for the forward pass of the source model, we'll have a chance of two tokens coming from\n",
    "the same/nearby prompts as very small.\n",
    "\n",
    "The conclusion is therefore that we do a need some sort of buffer, as we can't store 40TB on disk\n",
    "easily, and this buffer can be disk or ram. It needs to store asynchronously (so it doesn't block\n",
    "the forward pass), and it needs to be able to handle multiple simultaneous writes from e.g.\n",
    "distributed GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Fetching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Activations (Forward Pass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activations Buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
